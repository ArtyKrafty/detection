RUS | [ENG](#ENG)

<a id='RUS'></a>
<h2 align="center">–ú–æ–¥—É–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenCV –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ Python —Å –ø–æ–º–æ—â—å—é Detectron2. Pipeline, web-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏ –ª–æ–∫–∞–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ </h2>

<p align="center"><img src='https://i.ibb.co/rbJmBSV/Computer-Vision-Object-Detection-original.jpg'></p>

<a id='link6'></a>



–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:  

 [–í–≤–µ–¥–µ–Ω–∏–µ](#link1)  
- [–õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞](#link2)  
   - [–°–∫—Ä–∏–ø—Ç process_img.py](#link3)  
   - [–°–∫—Ä–∏–ø—Ç process_video.py](#link4)   
- [Web-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ](#link5) 
- [Dockerfile](#link)
- [–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞](#linkprobru)
- [–°—Å—ã–ª–∫–∏](#linkru001)


---

üìù –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≤ —Å–ø—è—â–µ–º —Ä–µ–∂–∏–º. –î–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –≤—Ä–µ–º—è. –¢–∞–∫–∂–µ, –≤–æ–∑–º–æ–∂–Ω—ã —Å–±–æ–∏ –≤ —Ä–∞–±–æ—Ç–µ - –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ. 
–§–æ—Ç–æ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ —É–¥–∞–ª—è—é—Ç—Å—è. 


<p align="center"><img src="https://i.ibb.co/X4W8wCw/2022-01-03-02-23-14.png" alt="2022-01-03-02-23-14" border="0"></p>


üìù –û—à–∏–±–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω–∞ —Å –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ–º –ø–∞–º—è—Ç–∏. –ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤–∑—è—Ç—å –¥—Ä—É–≥—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É. –° –ª–æ–∫–∞–ª—å–Ω–æ–π —Å–±–æ—Ä–∫–æ–π –ø—Ä–æ–±–ª–µ–º –Ω–µ –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç

---


<h3>–í–≤–µ–¥–µ–Ω–∏–µ</h3><a id='link1'></a>

–ú–æ–¥—É–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º [OpenCV](https://opencv.org/) –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ `Python` —Å –ø–æ–º–æ—â—å—é [Detectron2](https://github.com/facebookresearch/detectron2). –ò–¥–µ—è –º–æ–¥—É–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã–π `pipeline` –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º–∏ `DS`. –ò–¥–µ—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –≤–∑—è—Ç–∞ —É [Aros≈Çaw Gilewski](https://medium.com/deepvisionguru/modular-image-processing-pipeline-using-opencv-and-python-generators-9edca3ccb696) - –≤ –∏—Ç–æ–≥–µ –ø–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –¥–æ–ø–æ–ª–Ω—è—Ç—å—Å—è –≤ –Ω—É–∂–Ω—ã—Ö –Ω–∞–º –≤–∞—Ä–∏–∞—Ü–∏—è—Ö.  

–¶–µ–ª—å—é —Ä–∞–±–æ—Ç—ã –±—ã–ª–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–≤ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è `Detectron2` –∏ `OpenCV` –≤ –ø—Ä–æ–µ–∫—Ç—ã - –∫–∞–∫ –ª–æ–∫–∞–ª—å–Ω—ã–µ, —Ç–∞–∫ –∏ `web` —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥—É–ª–µ–π 
–∏–ª–∏ –∂–µ –≤ –≤–∏–¥–µ —Å–∫—Ä–∏–ø—Ç–æ–≤ —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–µ–π

> üìù –ï—Å–ª–∏ —É –í–∞—Å –Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è —Å—Å—ã–ª–∫–∞ –Ω–∞ `medium` - –≤–∫–ª—é—á–∏—Ç–µ —Ä–µ–∂–∏–º –∏–Ω–∫–æ–≥–Ω–∏—Ç–æ

1. **–õ–æ–∫–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ**. –í –¥–∞–Ω–Ω–æ–º –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–∏ - –≤—ã –º–æ–∂–µ—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ —Å–ª—É—á–∞–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏, –ª–∏–±–æ –ø—Ä–∏–º–µ–Ω—è—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
–æ—Ä—É–∂–∏—è, –≤ —Ç–æ–º —á–∏—Å–ª–µ –Ω–∞ –≤–∏–¥–µ–æ. –ü—Ä–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ–∑–≤–æ–ª—è–µ—Ç, –Ω–µ —É–≥–ª—É–±–ª—è—è—Å—å –≤ –∫–æ–¥, –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –≤ —Ç–æ–º —á–∏—Å–ª–µ –∏ –∑–∞—Ç–µ–Ω—è—Ç—å —Ñ–æ–Ω.

   –î–æ—Å—Ç—É–ø–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:  

      - –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
        - Instance segmentation –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
        - Keypoints
        - –ó–∞—Ç–µ–º–Ω–µ–Ω–∏–µ —Ñ–æ–Ω–∞ (separate background)
        - Panoptic segmentation
        - –î–µ—Ç–µ–∫—Ü–∏—è –æ—Ä—É–∂–∏—è (custom dataset)
      - –í–∏–¥–µ–æ:
        - Instance segmentation –Ω–∞ –≤–∏–¥–µ–æ
        - –ü–æ–∫–∞–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
        - –î–µ—Ç–µ–∫—Ü–∏—è –æ—Ä—É–∂–∏—è –Ω–∞ –≤–∏–¥–µ–æ
        
        
        
  <p align="center"><img src="https://i.ibb.co/ZJSL1yL/2021-12-28-10-43-20.png" alt="2021-12-28-10-43-20" border="0"></p>
  
  
 > üìù –ü–æ–¥–æ–π–¥–µ—Ç —Ç–µ–º, –∫—Ç–æ —Ö–æ—á–µ—Ç –∏–º–µ—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∫–æ–¥—É –∏ –∏–º–µ—Ç—å –±–æ–ª—å—à–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å. 
  
2. **Web-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ**. –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ `web-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ` —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é (—Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è) - –ù–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ –∞–¥—Ä–µ—Å—É: https://detartyseg.herokuapp.com/. –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é - –ø—Ä–∏—à–ª–æ—Å—å –æ–±—Ä–µ–∑–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª, –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Ä–∞–∑–º–µ—Ä–∞ –Ω–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ. –¢–∞–∫–∂–µ, –≤–æ–∑–º–æ–∂–µ–Ω –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ [Docker](https://www.docker.com/) - –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π —á–∞—Å—Ç–∏ —Ñ–∞–π–ª–∞ [Readme.md](#link) - –ª–æ–∫–∞–ª—å–Ω–æ, –ª–∏–±–æ –ø–æ—Å–ª–µ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è - –∑–∞–ø—É—Å —á–µ—Ä–µ–∑ `app_local.py`  

   –î–æ—Å—Ç—É–ø–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:  

      - –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
        - Instance segmentation –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
        - Keypoints –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
        - Panoptic segmentation –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö (`–£–î–ê–õ–ï–ù–û –∏–∑ web. –î–æ—Å—Ç—É–ø–Ω–æ –≤ docker`)
        - –ó–∞—Ç–µ–º–Ω–µ–Ω–∏–µ —Ñ–æ–Ω–∞ (separate background)
        - Blur —ç—Ñ—Ñ–µ–∫—Ç
        - –ß–µ—Ä–Ω–æ-–±–µ–ª–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ


<p align="center"><img src="https://i.ibb.co/mDCxTP3/2022-01-03-11-27-44.png" alt="2022-01-03-11-27-44" border="0"></p>
 
> üìù –ü–æ–¥–æ–π–¥–µ—Ç —Ç–µ–º, –∫—Ç–æ –Ω–µ —Ö–æ—á–µ—Ç —Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ - –∞ —Å—Ä–∞–∑—É –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –ï—Å—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –≤ –≤–∏–¥–µ [Docker](#link) —Å–±–æ—Ä–∫–∏

----
[–ö —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é](#link6)


<h3>–õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞</h3><a id='link2'></a>
<h4> 1. –°–∫—Ä–∏–ø—Ç process_img.py</h4><a id='link3'></a>

–ó–¥–µ—Å—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ —Ç—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏:   

- `instance segmentation` –Ω–∞ –∫–ª–∞—Å—Å—ã `COCO`
- `instance segmentation` –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ—Ä—É–∂–∏—è –Ω–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–º [–¥–∞—Ç–∞—Å–µ—Ç–µ](https://github.com/ArtyKrafty/detection/blob/main/configs/COCO-InstanceSegmentation_weapon/weapon_data.tar). –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±—ã–ª–∏ –≤–∑—è—Ç—ã —Å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è [MLWhiz](https://github.com/MLWhiz/object_detection), –∫–æ—Ç–æ—Ä—ã–µ —è —Ä–∞–∑–º–µ—Ç–∏–ª –≤—Ä—É—á–Ω—É—é —Å –ø–æ–º–æ—â—å—é [supervise.ly](https://supervise.ly/).    

–û–±—É—á–µ–Ω–∏–µ –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ —ç—Ç–æ–º [–Ω–æ—É—Ç–±—É–∫–µ](https://nbviewer.org/github/ArtyKrafty/detection/blob/main/configs/COCO-InstanceSegmentation_weapon/weapon_detection_ipynb__.ipynb), –µ—Å–ª–∏ –∑–∞—Ö–æ—Ç–∏—Ç–µ –æ–±—É—á–∏—Ç—å —Å–≤–æ–π –¥–µ—Ç–µ–∫—Ç–æ—Ä (–¥–æ—Å—Ç—É–ø–Ω–æ –∏ –≤ [Collab](https://colab.research.google.com/drive/1TOSFHYrQrxToQ4v5azP8xzpuLcgEKrQ3?usp=sharing)). –í–µ—Å–∞ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –º–æ–∂–Ω–æ –±—Ä–∞—Ç—å –∏–∑ [–∑–æ–æ–ø–∞—Ä–∫–∞](https://github.com/facebookresearch/detectron2/blob/main/detectron2/model_zoo/model_zoo.py) - —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å `.yaml` –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º –≤ –ø–∞–ø–∫–µ `config`
- `separate background` - –æ—Ç–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞, –≤–º–µ—Å—Ç–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏. –ò–¥–µ—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ [Aros≈Çaw Gilewski](https://medium.com/deepvisionguru/how-to-embed-detectron2-in-your-computer-vision-project-817f29149461)
- `keypoints` - –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –ª—é–¥–µ–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö (`pose-flow`)
- `panoptic segmentation` - –¥–ª—è –ø–∞–Ω–æ–ø—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π


–î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∑–∞–ø—É—Å–∫–∞, –¥–∞–Ω–Ω–æ–º—É –º–æ–¥—É–ª—é –±—ã–ª–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –ø—Ä–æ—Å—Ç–æ–µ `GUI`, —Å –ø–æ–º–æ—â—å—é [GOOEY](https://github.com/chriskiehl/Gooey)

---

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ**  

–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –≤ `virtuenv`. –ù–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —à–∞–≥ - –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å

```python
pip install virtualenv
virtualenv detection
source detection/bin/activate
```


–¢–∞–∫–∂–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ—á–∏—Ç–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–æ –∫–æ–Ω—Ü–∞ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —É—Å—Ç–∞–Ω–æ–≤–∫–∏. –î–ª—è `Win` —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `Ubuntu 20.04.3 LTS` —Å `WLS2` –∏–ª–∏ `Conda` —Ç–µ—Ä–º–∏–Ω–∞–ª. –ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ, —á—Ç–æ–±—ã —É –≤–∞—Å —É–∂–µ —Å—Ç–æ—è–ª–∞ [Anaconda](https://www.anaconda.com/products/individual)


–®–∞–≥–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥—É–ª—è. 

```python
git clone https://github.com/ArtyKrafty/detection
pip install -r requirements_loc.txt
```

Detectron2 –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤ —Å–æ—Å–µ–¥–Ω–∏–π –∫–∞—Ç–∞–ª–æ–≥ —Å –ø–∞–ø–∫–æ–π –º–æ–¥—É–ª—è

<p align="center"><img src="https://i.ibb.co/R25y4Lx/2021-12-26-19-35-04.png" alt="2021-12-26-19-35-04" border="0"></p>

–î–ª—è Win —É –≤–∞—Å –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ Visual C++ 2015 build tools   
–ï—Å–ª–∏ –Ω–µ—Ç - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ [–æ—Ç—Å—é–¥–∞](https://www.microsoft.com/ru-ru/download/confirmation.aspx?id=48159)  - —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è [Detectron2](https://github.com/philferriere/cocoapi)


–¢–∞–∫–∂–µ, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–µ—Ä—Å–∏—é torch –∏ torchvision - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–∂–Ω–æ [—Ç—É—Ç](https://pytorch.org/get-started/locally/) - 
–≤—ã–±–∏—Ä–∞–µ–º Package - –∫–æ–ø–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏


<p align="center"><img src="https://i.ibb.co/wc1NPMq/123.jpg" alt="123" border="0"></p> 


> üìù –ï—Å–ª–∏ —É –≤–∞—Å –ø–æ—è–≤–ª—è–µ—Ç—Å—è –æ—à–∏–±–∫–∞ - `Torchvision error: Could not find module image.pyd` - —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è [–∑–¥–µ—Å—å](https://kontext.tech/column/python/915/torchvision-error-could-not-find-module-imagepyd) —Å —Ä–µ—à–µ–Ω–∏–µ–º

–ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è `CPU`:

```python
pip3 install torch torchvision torchaudio
–∏–ª–∏
conda install pytorch torchvision cpuonly -c pytorch

```
–£—Å—Ç–∞–Ω–æ–≤–∫–∞ `Detectron2`

```python
cd

git clone https://github.com/facebookresearch/detectron2.git
python -m pip install -e detectron2

# –ù–∞ macOS, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–∞–∫ (–æ—Å–æ–±–µ–Ω–Ω–æ, –µ—Å–ª–∏ —É –≤–∞—Å M1)
CC=clang CXX=clang++ ARCHFLAGS="-arch x86_64" python -m pip install -e detectron2

–ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–Ω—É—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏, –º–æ–∂–Ω–æ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

–Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–∞—è –ø—Ä–æ–±–ª–µ–º–∞ - –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –°++ compiler 
conda install -c conda-forge compilers

```
[–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ Detectron2](https://github.com/facebookresearch/detectron2/blob/3def12bdeaacd35c6f7b3b6c0097b7bc31f31ba4/INSTALL.md).   
[–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ Detectron2. Installation](https://detectron2.readthedocs.io/en/latest/tutorials/install.html)

___

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è**


1. `Instance segmentation` –Ω–∞ –∫–ª–∞—Å—Å—ã `COCO`

```python
–û—Ç–∫—Ä—ã–≤–∞–µ–º —Ç–µ—Ä–º–∏–Ω–∞–ª

cd detection
pythonw process_img.py

```

> üìù –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –≤—ã–∑–æ–≤ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ `pythonw`, –Ω–µ `python` –∏–ª–∏ `python3`

–£ –≤–∞—Å –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –æ–∫–Ω–æ:

<p align="center"><img src="https://i.ibb.co/ZJSL1yL/2021-12-28-10-43-20.png" alt="2021-12-28-10-43-20" border="0"></p>


```python
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞—Ç—å input. –≠—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥—É—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –æ–±—ä–µ–∫—Ç—ã. 
–í—ã –º–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –º–æ–∏–º–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º–∏ - –ø–∞–ø–∫–∞

./examples/images/photo/

—Ç–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –ø–æ—Ä–æ–≥ confidence. 
–ù–∞–∂–∏–º–∞–µ–º START –∏ –≤ –ø–∞–ø–∫–µ outputs —É –≤–∞—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

```
<p align="center"><img src="https://i.ibb.co/pz0Twxx/0299ce77-30e4-4b31-b8e5-fad85b140111.jpg" alt="0299ce77-30e4-4b31-b8e5-fad85b140111" border="0"></p>


2. `Instance segmentation` –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ—Ä—É–∂–∏—è –Ω–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–º [–¥–∞—Ç–∞—Å–µ—Ç–µ](https://github.com/ArtyKrafty/detection/blob/main/configs/COCO-InstanceSegmentation_weapon/weapon_data.tar). –ù–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–ª–∞—Å—Å–æ–≤ –ø—Ä–∏—à–ª–æ—Å—å –ø—Ä–µ–Ω–µ–±—Ä–µ—á—å - –∏–Ω–∞—á–µ –ø–æ—Ç–µ—Ä—è–ª–∏ –≤ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç–∏. –ï—Å–ª–∏ —Å–æ–±—Ä–∞—Ç—å —Å–µ—Ç –±–æ–ª—å—à–µ - –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–¥–æ–±–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
–Ω–∞–ª–∏—á–∏—è –æ—Ä—É–∂–∏—è —É —á–µ–ª–æ–≤–µ–∫–∞

```python
–û—Ç–∫—Ä—ã–≤–∞–µ–º —Ç–µ—Ä–º–∏–Ω–∞–ª

cd detection
pythonw process_img.py

```

> üìù –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –≤—ã–∑–æ–≤ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ `pythonw`, –Ω–µ `python` –∏–ª–∏ `python3`

–£ –≤–∞—Å –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –æ–∫–Ω–æ:

<p align="center"><img src="https://i.ibb.co/1TmBmfX/2021-12-28-10-10-42.png" alt="2021-12-28-10-10-42" border="0"></p>


```python
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞—Ç—å input. –≠—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥—É—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –æ–±—ä–µ–∫—Ç—ã. 
–í—ã –º–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –º–æ–∏–º–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º–∏ - –ø–∞–ø–∫–∞

./examples/images/weapon/

—Ç–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –ø–æ—Ä–æ–≥ confidence. –¢—É—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å - 
–≤—ã –Ω–∞–π–¥–µ—Ç–µ –Ω—É–∂–Ω—É—é –≤ –ø–∞–ø–∫–µ config (–∏ –≤–µ—Å–∞ –∫ –Ω–µ–π):   


–ø—É—Ç—å ./detection/configs/COCO-InstanceSegmentation_weapon/mask_rcnn_R_50_FPN_3x.yaml. 
–ì—Ä—É–∑–∏–º –∫ –Ω–µ–π –≤–µ—Å–∞: ./detection/configs/COCO-InstanceSegmentation_weapon/model_final.pth
–ù–∞–∂–∏–º–∞–µ–º START –∏ –≤ –ø–∞–ø–∫–µ outputs —É –≤–∞—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
```
<p align="center"><img src="https://i.ibb.co/8M9Bt3T/new-use-hotel-robber-with-gun-2.jpg" alt="new-use-hotel-robber-with-gun-2" border="0"></p>

3. –û—Ç–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞ - —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ - –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ç–º–µ—Ç–∫—É separate_background

```python
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞—Ç—å input. –≠—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥—É—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –æ–±—ä–µ–∫—Ç—ã. 
–í—ã –º–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –º–æ–∏–º–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º–∏ - –ø–∞–ø–∫–∞

./examples/images/photos/

—Ç–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –ø–æ—Ä–æ–≥ confidence. –¢—É—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å - 
–≤—ã –Ω–∞–π–¥–µ—Ç–µ –Ω—É–∂–Ω—É—é –≤ –ø–∞–ø–∫–µ config (–∏ –≤–µ—Å–∞ –∫ –Ω–µ–π):   


–ø—É—Ç—å ./detection/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml. 
–°—Ç–∞–≤–∏–º –æ—Ç–º–µ—Ç–∫—É - separate background:
–ù–∞–∂–∏–º–∞–µ–º START –∏ –≤ –ø–∞–ø–∫–µ outputs —É –≤–∞—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

```

–ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å blur-—ç—Ñ—Ñ–µ–∫—Ç–æ–º –Ω–∞ —Ñ–æ–Ω - –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–∞—Å–∫—É –∏ –≤–º–µ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ–ª—É—á–∞–µ–º –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–π –æ—Ç —Ñ–æ–Ω–∞ –æ–±—ä–µ–∫—Ç—Ä

<p align="center"><img src="https://i.ibb.co/Q9m5nHh/004.jpg" alt="004" border="0"></p>

4. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫:

```python
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞—Ç—å input. –≠—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥—É—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –æ–±—ä–µ–∫—Ç—ã. 
–í—ã –º–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –º–æ–∏–º–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º–∏ - –ø–∞–ø–∫–∞

./examples/images/key_points/

—Ç–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –ø–æ—Ä–æ–≥ confidence. –¢—É—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å - 
–≤—ã –Ω–∞–π–¥–µ—Ç–µ –Ω—É–∂–Ω—É—é –≤ –ø–∞–ø–∫–µ config (–∏ –≤–µ—Å–∞ –∫ –Ω–µ–π):   


–ø—É—Ç—å ./detection/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml. 
–ù–∞–∂–∏–º–∞–µ–º START –∏ –≤ –ø–∞–ø–∫–µ outputs —É –≤–∞—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

–í–µ—Å–∞ –∑–∞–¥–∞–≤–∞—Ç—å –Ω–µ –Ω–∞–¥–æ. 

```
–ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –æ—Ç–º–µ—á–µ–Ω–Ω—ã–º–∏ –∫–ª—é—á–µ–≤—ã–º–∏ —Ç–æ—á–∫–∞–º–∏. –ü—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ —Å –ª—é–¥—å–º–∏. 


<p align="center"><img src="https://i.ibb.co/0KY5Jh1/predict.jpg" alt="predict" border="0"></p>

5. –ü–∞–Ω–æ–ø—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–∫–∞–∑–∞—Ç—å –∞–¥—Ä–µ—Å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
```python
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞—Ç—å input. –≠—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥—É—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –æ–±—ä–µ–∫—Ç—ã. 
–í—ã –º–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –º–æ–∏–º–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º–∏ - –ø–∞–ø–∫–∞

./examples/images/pan/

—Ç–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –ø–æ—Ä–æ–≥ confidence. –¢—É—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å - 
–≤—ã –Ω–∞–π–¥–µ—Ç–µ –Ω—É–∂–Ω—É—é –≤ –ø–∞–ø–∫–µ config (–∏ –≤–µ—Å–∞ –∫ –Ω–µ–π):   


–ø—É—Ç—å ./detection/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml 
–ù–∞–∂–∏–º–∞–µ–º START –∏ –≤ –ø–∞–ø–∫–µ outputs —É –≤–∞—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

–í–µ—Å–∞ –∑–∞–¥–∞–≤–∞—Ç—å –Ω–µ –Ω–∞–¥–æ. 

```

<p align="center"><img src="https://i.ibb.co/Zx9zB1g/predict.jpg" alt="predict" border="0"></p>


–¶–µ–ª—å—é –±—ã–ª–æ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ –±–µ–∑ —É–≥–ª—É–±–ª–µ–Ω–∏–π –≤ –∫–æ–¥ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–∞–Ω–Ω–æ–≥–æ –º–æ–¥—É–ª—è

----
[–ö —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é](#link6)

<h4> 2. –°–∫—Ä–∏–ø—Ç process_video.py</h4><a id='link4'></a>

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è**


`Instance segmentation` –Ω–∞ –∫–ª–∞—Å—Å—ã `COCO`

```python
–û—Ç–∫—Ä—ã–≤–∞–µ–º —Ç–µ—Ä–º–∏–Ω–∞–ª

cd detection
pythonw process_video.py

```

> üìù –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –≤—ã–∑–æ–≤ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ `pythonw`, –Ω–µ `python` –∏–ª–∏ `python3`. –ü—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π. –ú–æ–∂–Ω–æ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –æ—Ä—É–∂–∏–µ - 
> –ø–æ —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è–º —ç—Ç–∏–∫–∏ - –±—ã–ª–æ –ø—Ä–∏–Ω—è—Ç–æ –Ω–µ –¥–æ–±–∞–≤–ª—è—Ç—å —Ñ–∞–π–ª —Å –≤–æ–æ—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –Ω–∞–ø–∞–¥–µ–Ω–∏—è–º–∏ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π

–£ –≤–∞—Å –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –æ–∫–Ω–æ:

<p align="center"><img src="https://i.ibb.co/KKBhVRy/2021-12-27-23-26-40.png" alt="2021-12-27-23-26-40" border="0"></p>

```python
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞—Ç—å input. –≠—Ç–æ –≤–∏–¥–µ–æ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥—É—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –æ–±—ä–µ–∫—Ç—ã. 
–í—ã –º–æ–∂–µ—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –º–æ–∏–º–∏ –ø—Ä–∏–º–µ—Ä–æ–º

./examples/videos/cross_roads.mp4

—Ç–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –ø–æ—Ä–æ–≥ confidence. 
–ù–∞–∂–∏–º–∞–µ–º START –∏ –≤ –ø–∞–ø–∫–µ outputs —É –≤–∞—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ. –ó–∞–Ω–∏–º–∞–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è

```
**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ.** –í–∞–∂–Ω–æ! –ù–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç [bug](https://github.com/facebookresearch/detectron2/issues/3780) –Ω–∞ –∫–ª–∞—Å—Å
`VideoVisualizer`. –ß—Ç–æ–±—ã –µ–≥–æ –æ–±–æ–π—Ç–∏, –±—ã–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫–ª–∞—Å—Å `Visualizer`, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
–ø–æ—ç—Ç–æ–º—É –º–∞—Å–∫–∏ –æ—Ç –∫–∞–¥—Ä–∞ –∫ –∫–∞–¥—Ä—É –º–µ–Ω—è—é—Ç—Å—è. –í–æ–∑–º–æ–∂–Ω–æ bug –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ M1 silicone

![](sample.gif)

----
[–ö —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é](#link6)

<h3>Web-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ</h3><a id='link5'></a>


–°–∫—Ä–∏–ø—Ç `app_local.py` - –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ



–∑–µ—Ä–∫–∞–ª–æ –¥–ª—è `app.py`, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ –∞–¥—Ä–µ—Å—É: https://detartyseg.herokuapp.com/. 
–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é - –ø—Ä–∏—à–ª–æ—Å—å –æ–±—Ä–µ–∑–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª, –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Ä–∞–∑–º–µ—Ä–∞ –Ω–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ. –ü—Ä–∏—à–ª–æ—Å—å —É–±—Ä–∞—Ç—å –ø–∞–Ω–æ–ø—Ç–∏—á–µ—Å–∫—É—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é -
–ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ –Ω–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–º —Å–µ—Ä–≤–µ—Ä–µ. –û—Å—Ç–∞–ª—Å—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∏ `docker`

–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ  - –∑–∞–ø—É—Å–∫–∞–µ–º `app_local.py`:


```python
 git clone https://github.com/ArtyKrafty/detection
 cd detection
 python app_local.py
 
```
–ó–∞–ø—É—Å—Ç–∏—Ç—Å—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º –ø–æ –∞–¥—Ä–µ—Å—É - `http://–í–ê–®_URL_–∏–∑_—Ç–µ—Ä–º–∏–Ω–∞–ª–∞:8080/`


<p align="center"><img src="https://i.ibb.co/mDCxTP3/2022-01-03-11-27-44.png" alt="2022-01-03-11-27-44" border="0"></p>

–ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ä–∞–±–æ—á–µ–≥–æ —Å—Ç–æ–ª–∞, –≤—ã–¥–µ–ª–∏—Ç—å –º–∞—Å–∫–∏ –Ω–∞ –Ω–µ–º –∏–ª–∏ –∑–∞—Ç–µ–º–Ω–∏—Ç—å —Ñ–æ–Ω. –¢–∞–∫–∂–µ –≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ `URL` - —Ç–æ–ª—å–∫–æ instance segmentation

<a id='link'></a>

–î—Ä—É–≥–æ–π –≤–∞—Ä–∏–∞–Ω—Ç - –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ `Docker` (–ª–æ–∫–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è https://detartyseg.herokuapp.com/) - –≤–µ—Å –æ–±—Ä–∞–∑–∞ `~14.1 GB` (—É –≤–∞—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
[Docker](https://www.docker.com/) - –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –Ω–∏—á–µ–≥–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è):

```python
git clone https://github.com/ArtyKrafty/detection

cd detection

docker build . -f Dockerfile -t detectron2
docker run --name detectron2 -p 127.0.0.1:8080:8080 detectron2


–∑–∞—Ç–µ–º - –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –∑–∞–∫–æ–Ω—á–∏–ª–∏:

docker stop detectron2
docker rm $(docker ps -qa)

–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å docker-desktop –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, —á—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —É–¥–æ–±–Ω–µ–µ

–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤–Ω—É—Ç—Ä–∏: docker run -t -i detectron2 /bin/bash
```
<p align="center"><img src="https://i.ibb.co/FwgVWJn/123.jpg" alt="123" border="0"></p>

> üìù –ï—Å–ª–∏ —É –≤–∞—Å `MacOS` - –∑–∞–π–¥–∏—Ç–µ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ `docker -> advanced` –∏ —É–≤–µ–ª–∏—á—å—Ç–µ –ø–∞–º—è—Ç—å `RAM` —Å 2 –¥–æ 4 –ì–ë - –∏–Ω–∞—á–µ `–°++` –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä 
–Ω–µ —Å–º–æ–∂–µ—Ç —Å–æ–±—Ä–∞—Ç—å `torch`

----
[–ö —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é](#link6)

<h3>–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞</h3><a id='linkprobru'></a>

–ü—Ä–æ–±–ª–µ–º—ã –≤–æ–∑–Ω–∏–∫–∞—é—Ç –Ω–µ —Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º, –∞ –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–æ–ø—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è - `Detectron2`, `torch` –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ. 
–ó–¥–µ—Å—å —Å–æ–±—Ä–∞–ª —Ä–µ—à–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –≤–∞–º –≤ —É—Å—Ç–∞–Ω–æ–≤–∫–µ, –µ—Å–ª–∏ –≤—ã —Ä–µ—à–∏—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ —á–µ—Ä–µ–∑ `docker`. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–æ—Å—å –Ω–∞ `MacOs` –∏ `Windows` - –Ω–∞ `Win` - –æ—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ - –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ `Microsoft Visual C++`. –î–∞–Ω–Ω—ã–π —Å–±–æ—Ä–Ω–∏–∫ –ø–æ–º–æ–∂–µ—Ç —Ä–µ—à–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ `torch` –∏ `Detectron2`. –¢–∞–∫–∂–µ, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é, —á—Ç–æ–±—ã —É –≤–∞—Å —É–∂–µ –±—ã–ª–∞ `Anaconda`

| –ò—Å—Ç–æ—á–Ω–∏–∫  |  –û–ø–∏—Å–∞–Ω–∏–µ |  –†–µ—à–µ–Ω–∏–µ |
|---|---|---|
| –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Web-app  | –ü–æ—è–≤–ª—è–µ—Ç—Å—è –æ—à–∏–±–∫–∞ `heroku` - `Application Error`  | –û—à–∏–±–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω–∞ —Å –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ–º –ø–∞–º—è—Ç–∏. –ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –µ—â–µ —Ä–∞–∑ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ –∏–ª–∏ –≤–∑—è—Ç—å –¥—Ä—É–≥—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É. –° –ª–æ–∫–∞–ª—å–Ω–æ–π —Å–±–æ—Ä–∫–æ–π –ø—Ä–æ–±–ª–µ–º –Ω–µ –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç  |
|  torch, Detectron | C++ –æ—à–∏–±–∫–∞ –Ω–∞ Windows –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –Ω–∞ `pycatools`  |  –£ –≤–∞—Å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω Visual Studio C++ - –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ [–æ—Ç—Å—é–¥–∞](https://www.microsoft.com/ru-ru/download/confirmation.aspx?id=48159) |
| torch, torchvision  | —É—Å—Ç–∞—Ä–µ–≤—à–∞—è –≤–µ—Ä—Å–∏—è –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—é—â–∞—è –≤–∞—à–µ–º—É –ü–ö  | –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–∂–Ω–æ [—Ç—É—Ç](https://pytorch.org/get-started/locally/)|
| torch  | `Torchvision error: Could not find module image.pyd`  | –æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è [–∑–¥–µ—Å—å](https://kontext.tech/column/python/915/torchvision-error-could-not-find-module-imagepyd) —Å —Ä–µ—à–µ–Ω–∏–µ–º  |
| Docker  | –æ—à–∏–±–∫–∞ —Å `–°++` –ø—Ä–∏ —Å–±–æ—Ä–∫–µ –∏–ª–∏ `os` | –∑–∞–π–¥–∏—Ç–µ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ `docker -> advanced` –∏ —É–≤–µ–ª–∏—á—å—Ç–µ –ø–∞–º—è—Ç—å `RAM` —Å 2 –¥–æ 4 –ì–ë|

----
[–ö —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é](#link6)

<h3>–°—Å—ã–ª–∫–∏</h3><a id='linkru001'></a>

1. [–ö—É—Ä—Å Deep learning school](https://www.dlschool.org/pro-track) - –æ–±—É—á–∞—é—Ç –∏ –Ω–∞–ø—Ä–∞–≤–ª—è—é—Ç. 
2. [Aros≈Çaw Gilewski](https://medium.com/deepvisionguru/modular-image-processing-pipeline-using-opencv-and-python-generators-9edca3ccb696) - –∏–Ω–∂–µ–Ω–µ—Ä CV. –ò–¥–µ—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ python –∏ –∑–∞ baseline —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞. 
3. [Detectron2](https://github.com/facebookresearch/detectron2) - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Meta –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ —Å –æ–≥—Ä–æ–º–Ω—ã–º –∑–æ–æ–ø–∞—Ä–∫–æ–º –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.   
4. [OpenCV](https://opencv.org/) - —Å—Ä–µ–¥—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ë–µ–∑ —ç—Ç–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –±—ã–ª–æ –±—ã —Å–ª–æ–∂–Ω–µ–µ. 
5. [Heroku](https://www.heroku.com/) - –±—ã—Å—Ç—Ä—ã–π —Å–ø–æ—Å–æ–± —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π. 
6. [pyTorch](https://pytorch.org/docs/stable/torch.html) - —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ —Å–µ—Ç—è–º–∏  
7. [Docker](https://www.docker.com/) - —Å—Ä–µ–¥—Å—Ç–≤–æ —É–ø–∞–∫–æ–≤–∫–∏ –∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π  
8. [MLWhiz](https://github.com/MLWhiz/object_detection) - –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –æ–±—Ä–∞–∑—Ü—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏

----
[–ö —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é](#link6)

[RUS](#RUS) | ENG

<a id='ENG'></a>

<h2 align="center">Modular image and video processing with OpenCV and Detectron2. Pipeline, web-app and local-app </h2>


<p align="center"><img src='https://i.ibb.co/rbJmBSV/Computer-Vision-Object-Detection-original.jpg'></p>
<a id='RUS'></a>
<a id='link7'></a>


Table of content:  

- [Introduction](#link8)  
- [Local installation](#link9)  
   - [Script process_img.py](#link10)  
   - [Script process_video.py](#link11)   
- [Web-application](#link12) 
- [Dockerfile](#linkdock)
- [Help desk](#linkprobeng)
- [Credits](#linkeng001)


---


üìù Application is in sleep mode. It will take time to launch. Also, malfunctions are possible - the application is on a free server.
Photos are deleted after upload.

<p align="center"><img src="https://i.ibb.co/X4W8wCw/2022-01-03-02-23-14.png" alt="2022-01-03-02-23-14" border="0"></p>


üìù The error may be related to out of memory. You can try again or take another picture. There will be no problems with local assembly

---


<h3>Introduction</h3><a id='link8'></a>

Modular image processing using [OpenCV](https://opencv.org/) and `Python` generators using [Detectron2](https://github.com/facebookresearch/detectron2). The idea of modularity allows the industrial processing pipeline to be programmed by several `DS` specialists. The idea of using generators is taken from [Aros≈Çaw Gilewski](https://medium.com/deepvisionguru/modular-image-processing-pipeline-using-opencv-and-python-generators-9edca3ccb696) - as a result, we get a full-fledged module that can be supplemented in the variations we need.

The aim of the work was to implement various approaches to integrating `Detectron2` and `OpenCV` into projects - both local and web using modules
or in the form of scripts using different versions of the models

> üìù If you do not have a link to `medium` - turn on incognito mode

1. **Local execution**. In this version, you can work with random images, or use a trained model for detection
weapons, including video. By expanding the training data, you can get more accurate results.
The interface allows, without delving into the code, to perform image segmentation, including shading the background.

  Available functionality:

      - Images:
        - Instance segmentation on images
        - Key points
        - Panoptic segmentation
        - Separate background
        - Weapon detection (custom data set)
      - Video:
        - Instance segmentation on video
        - Show processing in real time
        - Weapon detection on video
        
  <p align="center"><img src="https://i.ibb.co/ZJSL1yL/2021-12-28-10-43-20.png" alt="2021-12-28-10-43-20" border="0"></p>

2. **Web Application**. An additional web application with limited functionality has been implemented (only images) - Located at: https://detartyseg.herokuapp.com/. Unfortunately, I had to cut the functionality due to the size restrictions for the application. Also, launching via [Docker](https://www.docker.com/) is possible - instructions in the corresponding part of the file [Readme.md](#linkdock) - locally, or after cloning the repository - launching via `app_local.py`

 Available functionality:

      - Images:
        - Instance segmentation on images
        - Keypoints on images
        - Panoptic segmentation (Deleted from web. Only in docker)
        - Separate background
        - Blur effect
        - Black and white image


<p align="center"><img src="https://i.ibb.co/mDCxTP3/2022-01-03-11-27-44.png" alt="2022-01-03-11-27-44" border="0"></p>


----
[Back to contest](#link7)


<h3>Local execution</h3><a id='link9'></a>
<h4> 1. Script process_img.py</h4><a id='link10'></a>

Here are three options for how the model works:

- `instance segmentation` into classes` COCO`
- `instance segmentation` for detecting weapons on a custom [dataset](https://github.com/ArtyKrafty/detection/blob/main/configs/COCO-InstanceSegmentation_weapon/weapon_data.tar). The images were taken from the [MLWhiz](https://github.com/MLWhiz/object_detection) repository, which I mapped out manually using [supervise.ly](https://supervise.ly/).

You can watch the training in this [notebook](https://nbviewer.org/github/ArtyKrafty/detection/blob/main/configs/COCO-InstanceSegmentation_weapon/weapon_detection_ipynb__.ipynb), if you want to train your detector (available in [Collab](https://colab.research.google.com/drive/1TOSFHYrQrxToQ4v5azP8xzpuLcgEKrQ3?usp=sharing)). The weights of the base models can be taken from the [zoo](https://github.com/facebookresearch/detectron2/blob/main/detectron2/model_zoo/model_zoo.py) - form `.yaml` similarly to those presented in the` config` folder
- `separate background` - separation of the background, instead of annotation. Idea suggested by [Aros≈Çaw Gilewski](https://medium.com/deepvisionguru/how-to-embed-detectron2-in-your-computer-vision-project-817f29149461)
- `keypoints` - for building key points of people on images (` pose-flow`). 

For ease of launch, a simple `GUI` was added to this module, using [GOOEY](https://github.com/chriskiehl/Gooey)

---

**Install locally**

It is recommended to install to `virtuenv`. Optional step - can be skipped

```python
pip install virtualenv
virtualenv detection
source detection/bin/activate
```


It is also recommended to read the instructions to the end before starting the installation. For `Win` it is recommended to use` Ubuntu 20.04.3 LTS` with `WLS2` or` Conda` terminal. It is desirable that you already have [Anaconda](https://www.anaconda.com/products/individual)


Module configuration steps.

```python
git clone https://github.com/ArtyKrafty/detection
pip install -r requirements_loc.txt
```

Detectron2 must be installed in the adjacent directory with the module folder

<p align="center"><img src="https://i.ibb.co/R25y4Lx/2021-12-26-19-35-04.png" alt="2021-12-26-19-35-04" border="0"></p>

For Win, you must have Visual C ++ 2015 build tools installed
If not, install [from here](https://www.microsoft.com/en-ru/download/confirmation.aspx?id=48159) - this is required for [Detectron2](https://github.com/philferriere/cocoapi)


Also, it is recommended to check the version of torch and torchvision - you can check [here](https://pytorch.org/get-started/locally/) - select Package - copy the command to install


<p align="center"><img src="https://i.ibb.co/wc1NPMq/123.jpg" alt="123" border="0"></p>


> üìù If you get an error - `Torchvision error: Could not find module image.pyd` - I recommend reading [here](https://kontext.tech/column/python/915/torchvision-error-could-not-find-module-imagepyd) with solution

For example, for `CPU`:

```python
pip3 install torch torchvision torchaudio
–∏–ª–∏
conda install pytorch torchvision cpuonly -c pytorch

```
`Detectron2` installation

```python
cd

git clone https://github.com/facebookresearch/detectron2.git
python -m pip install -e detectron2

# On macOS, you need to install like this (especially if you have M1
CC=clang CXX=clang++ ARCHFLAGS="-arch x86_64" python -m pip install -e detectron2

If you have any difficulties, you can refer to the official documentation

the most common problem is the lack of a C ++ compiler:
conda install -c conda-forge compilers

```
[Detectron2 Official Installation Guide](https://github.com/facebookresearch/detectron2/blob/3def12bdeaacd35c6f7b3b6c0097b7bc31f31ba4/INSTALL.md).  
[Official Installation Guide for Detectron2. Installation](https://detectron2.readthedocs.io/en/latest/tutorials/install.html)

___

**Module usage**


1. `Instance segmentation` with `COCO`

```python
Open terminal

cd detection
pythonw process_img.py

```

> üìù Note that the call is made through `pythonw`, not` python` or `python3`

A window will open:

<p align="center"><img src="https://i.ibb.co/ZJSL1yL/2021-12-28-10-43-20.png" alt="2021-12-28-10-43-20" border="0"></p>


```python
You must set input. These are the images on which objects will be predicted.
You can use my photos - folder

./examples/images/photo/

also you can choose the confidence threshold.
Press START and in the outputs folder you have processed images
```
<p align="center"><img src="https://i.ibb.co/pz0Twxx/0299ce77-30e4-4b31-b8e5-fad85b140111.jpg" alt="0299ce77-30e4-4b31-b8e5-fad85b140111" border="0"></p>


2. `Instance segmentation` for detecting weapons on a custom [dataset](https://github.com/ArtyKrafty/detection/blob/main/configs/COCO-InstanceSegmentation_weapon/weapon_data.tar). The class names had to be neglected - otherwise they lost in universality. If you collect a larger set, you can use similar models to detect whether a person has a weapon

```python
Open terminal

cd detection
pythonw process_img.py

```

> üìù Note that the call is made through `pythonw`, not` python` or `python3`

A window will open:

<p align="center"><img src="https://i.ibb.co/1TmBmfX/2021-12-28-10-10-42.png" alt="2021-12-28-10-10-42" border="0"></p>


```python
You must set input. These are the images on which objects will be predicted.
You can use my photos - folder

./examples/images/weapon/

also you can choose the confidence threshold. Here you need to change the model -
you will find the needed one in the config folder (and weights to it):


path ./detection/configs/COCO-InstanceSegmentation_weapon/mask_rcnn_R_50_FPN_3x.yaml.
We load weights to it: ./detection/configs/COCO-InstanceSegmentation_weapon/model_final.pth
Press START and in the outputs folder you have processed images
```
<p align="center"><img src="https://i.ibb.co/8M9Bt3T/new-use-hotel-robber-with-gun-2.jpg" alt="new-use-hotel-robber-with-gun-2" border="0"></p>

3. Separating the background - works the same way - just check the separate_background

```python
You must set input. These are the images on which objects will be predicted.
You can use my photos - folder

./examples/images/photos/

also you can choose the confidence threshold. Here you need to change the model -
you will find the needed one in the config folder (and weights to it):


path ./detection/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml.
We put a mark - separate background:
Press START and in the outputs folder you have processed images

```

Getting an image with a blur effect on the background

<p align="center"><img src="https://i.ibb.co/Q9m5nHh/004.jpg" alt="004" border="0"></p>

4. Building key points - works similarly to weapons - just specify the address to the configuration
```python
You must set input. These are the images on which objects will be predicted.
You can use my photos - folder

./examples/images/key_points/

also you can choose the confidence threshold. Here you need to change the model -
you will find the needed one in the config folder (and weights to it):


path ./detection/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml.
Press START and in the outputs folder you have processed images

There is no need to set weights.

```
We get an image with marked key points.


<p align="center"><img src="https://i.ibb.co/0KY5Jh1/predict.jpg" alt="predict" border="0"></p>

5. Panoptic group of images - just specify the address to the configuration

```python
You must set input. These are the images on which objects will be predicted.
You can use my photos - folder

./examples/images/pan/

also you can choose the confidence threshold. Here you need to change the model -
you will find the needed one in the config folder (and weights to it):


path ./detection/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml
Press START and in the outputs folder you have processed images

There is no need to set weights.

```

<p align="center"><img src="https://i.ibb.co/Zx9zB1g/predict.jpg" alt="predict" border="0"></p>

The goal was to demonstrate various options for the model without delving into the code on the part of the user of this module - it is enough to specify the address to the configuration

----
[Back to contest](#link7)

<h4> 2. Script process_video.py</h4><a id='link11'></a>

**Module usage**


`Instance segmentation` with `COCO`

```python
Open terminal

cd detection
pythonw process_video.py

```

> üìù Note that the call is made through `pythonw`, not` python` or `python3`. The principle of operation is similar. Weapons can also be detected -
for ethical reasons - it was customary not to add the file with armed attacks to the repository

A window will open:

<p align="center"><img src="https://i.ibb.co/KKBhVRy/2021-12-27-23-26-40.png" alt="2021-12-27-23-26-40" border="0"></p>

```python
You must set input. This is a video in which objects will be predicted.
You can use my example

./examples/videos/cross_roads.mp4

also you can choose the confidence threshold.
Press START and in the outputs folder you have the processed video. Takes some time

```
> üìù Important! At the moment, there is a [bug](https://github.com/facebookresearch/detectron2/issues/3780) for the class
`VideoVisualizer`. To get around it, the `Visualizer` class was used, which is used for images
therefore the masks change from frame to frame. Probably the bug is only observed on M1 silicone

![](sample.gif)
----
[Back to contest](#link7)

<h3>Web-application</h3><a id='link12'></a>
Script app_local.py - for local work


mirror for `app.py`, which is located at: https://detartyseg.herokuapp.com/.
Unfortunately - I had to cut the functionality, due to the size restrictions for the application. I had to remove the `panoptic segmentation` -
memory excess on the application, on a free server. Remained functional in the local application and `docker`

If you want to run locally, run `app_local.py`:


```python
 git clone https://github.com/ArtyKrafty/detection
 cd detection
 python app_local.py
 
```

An application with limited functionality will start at the address - `http: // YOUR_URL_from_terminal: 8080 /`


<p align="center"><img src="https://i.ibb.co/mDCxTP3/2022-01-03-11-27-44.png" alt="2022-01-03-11-27-44" border="0"></p>

Here you can load an image from the desktop, select masks on it or darken the background. It is also possible to download images by `URL` - only instance segmentation

<a id='linkdock'></a>

Another option is to run via Docker (local copy of https://detartyseg.herokuapp.com/) - weight of Image 14.4 GB:

```python
git clone https://github.com/ArtyKrafty/detection
cd detection

docker build . -f Dockerfile -t detectron2
docker run --name detectron2 -p 127.0.0.1:8080:8080 detectron2


and after finish:

docker stop detectron2
docker rm $(docker ps -a -q)

or you can use docker-desktop app
look files inside: docker run -t -i detectron2 /bin/bash
```

<p align="center"><img src="https://i.ibb.co/FwgVWJn/123.jpg" alt="123" border="0"></p>

> üìù If you `MacOS` user - go to` docker -> advanced` settings and increase `RAM` from 2 to 4 GB - otherwise` C ++ `compiler
can't build `torch`. 


----
[Back to contest](#link7)

<h3>Help desk</h3><a id='linkprobeng'></a>

Problems do not arise with the application, but problems may arise when problems arise - `Detectron2`,` torch` and so on.
Here are some solutions to help you install if you choose to work outside of `docker`. Tested on `MacOs` and` Windows` - on `Win` - the main problem is the lack of` Microsoft Visual C++ `. This collection will help to solve the main problems when installing `torch` and` Detectron2`. Also, it is recommended to have Anaconda on board

| Problem  |  Description |  Solution |
|---|---|---|
| Web-app | Error `heroku` -` Application Error` appears | The error may be related to out of memory. You can try again to perform the action or take another picture. There will be no problems with local assembly |
| torch, Detectron | C ++ error on Windows when installing on `pycatools` | You do not have Visual Studio C ++ installed - the compiler is missing. Install [from here](https://www.microsoft.com/ru-ru/download/confirmation.aspx?id=48159) |
| torch, torchvision | outdated version or installed not matching your PC | you can check [here](https://pytorch.org/get-started/locally/) |
| torch | `Torchvision error: Could not find module image.pyd` | read [here](https://kontext.tech/column/python/915/torchvision-error-could-not-find-module-imagepyd) with a solution |
| Docker | error with `C ++` on assembly or `os` | go to `docker -> advanced` settings and increase the` RAM` memory from 2 GB to 4 GB |

----
[Back to contest](#link7)


<h3>Credits</h3><a id='linkeng001'></a>

1. [Deep learning school](https://www.dlschool.org/pro-track) - educate and guide.  
2. [Aros≈Çaw Gilewski](https://medium.com/deepvisionguru/modular-image-processing-pipeline-using-opencv-and-python-generators-9edca3ccb696) - CV engineer. Idea of using pipelines and separate background baseline.   
3. [Detectron2](https://github.com/facebookresearch/detectron2) - Meta library for working with images  
4. [OpenCV](https://opencv.org/) - video and image processing tool  
5. [Heroku](https://www.heroku.com/) - a fast way to develop and host applications  
6. [pyTorch](https://pytorch.org/docs/stable/torch.html) - framework for working with neural networks  
7. [Docker](https://www.docker.com/) - packaging and image transfer tool
8. [MLWhiz](https://github.com/MLWhiz/object_detection) - provided sample images for markup


----
[Back to contest](#link7)
